---
title: 'Tidy Data'
author: "Jeremy Van Cleve"
output: html_document
date: 21th September 2016
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Outline for today

- So many data formats, so little time
- One format to rule them all: tidy data
- Making tidy data
- Slicing tidy data with `dplyr`

# So many data formats, so little time

> Happy families are all alike;  
> every unhappy family is unhappy in its own way.
>
> Leo Tolstoy (first line of "Anna Karenina")

Hadley Wickham points out the nice connection between the above quote and data formats [^1]. While data formatting might seem esoteric and boring, paying attention to it early on can pay off a great deal in the long term, which hopefully leads to a happy scientist. If one were to break data formatting into two phases, they might be these:

    Phase 1. The literal production of data itself from your experiment since you must choose a format and medium in which to record the data. 
    
    Phase 2. The input and formatting of data into your analysis tool (e.g., R). This might involve minimal changing of the "format" or a great deal of reshaping of the data.
    
Working backward, you do the least work on data formatting if you choose to save your data initially in a format that is easiest to analyze with R. Since we will use the graphing package, `ggplot2`, by Hadley Wickham, we will use the data format, **tidy data**, that he advocates. To get a sense for what his format is and why it might be useful, consider some different ways to organize data on tuberculosis (TB) cases where you have three variables, *country*, *year*, and *population*, for each measurement of *cases*. First, each variable including *cases* could have its own column:
```{r}
library(tidyr)
table1
```
Here, each row represents one time you measured the TB cases. Alternatively, you could have each row represent a country with columns for different years. This means you need a table that measures the *cases* and one that measures the *population*:
```{r}
table4a # cases
table4b # population
```

The latter format is actually the way we formatted the polling data from week 3 where we had one table for Hillary polls and one for Trump polls. The former format is the one we had for week 4 where a single table had both Hillary and Trump data. To see why the latter format might get cumbersome, suppose that we had polling data for all the candidates from the 2016 Republican primary, which started with 17 candidates (!). Using the latter format, we would need 17 tables to contain all the data, and would have to juggle between them as we compared polls between different candidates. With the first format, we can include all the candidates in a single table. The first format is the **tidy** format. 

# One format to rule them all: tidy data

The tidy format has the following three rules:

1. Each variable must have its own column.
2. Each observation must have its own row.
3. Each value must have its own cell.

Visually, this looks like
![](assets/tidy.png)

The primary benefit of tidy data is that every variable is a vector (column), which means that slicing data is just slicing columns. Though this may become complicated when the number of variables is large, there are some helper functions that will make slicing tidy data much easier. The slicing functions come from the package `dplyr` and the plotting package `ggplot2` assumes tidy data.

To give a flavor of the power of tidy data and `ggplot2`, you can easily (once you know more about ggplot2 and dplyr!) plot the polling data for Clinton and Trump (note that we are using 'up-to-date' date) on the same figure:
```{r}
library(readr)
library(ggplot2)

polls = read_csv("USPresPolls_538dotcom_21Sep2016.csv")

ggplot(subset(polls, ((polltypeA == "now") & (endDate > "2016-08-01"))), 
                         aes(y=adj_pct, x=endDate, group=choice, color=choice)) + 
  geom_point() + geom_line() +
  labs(title = "Vote percentage by date\n", 
     y = "Percent Vote if Election Today", x = "Poll Date", 
     color = "Candidate")
```

# Making tidy data

Often, data will not be in the tidy format by default, so it will be necessary to format it. The first step is to figure out what the "variables" and "observations" are. Sometimes this may require carefully thinking about the experimental design used to create the data. Two common problems with data that are *untidy* are:

1. One variable might be spread across multiple columns.
2. One observation might be scattered across multiple rows.

Typically, a dataset will only suffer one of the above problems. The first problem is dealt with using the `gather` function and the second with the `spread` function.

## Gathering data

Recall that this table is tidy
```{r}
table1
```
whereas these two are not
```{r}
table4a
table4b
```
The problem with `table4a` and `table4b` is that the variable *year* is spread across multiple columns. Thus, you need to `gather` it together. The columns `1999` and `2000` will be gathered as values of the variable *year*, which is called the `key`. The first table contains the number of cases
```{r}
# note that backticks `` here. we need them since the column names start with a number.
tidy4a = gather(table4a, `1999`, `2000`, key = "year", value = "cases") 
tidy4a
```
and the second table contains the population size
```{r}
tidy4b = gather(table4b, `1999`, `2000`, key = "year", value = "population") 
tidy4b
```
To join these two results together, you use the function `left_join`
```{r}
library(dplyr)
left_join(tidy4a, tidy4b)
```
which is the same as the first table (rows are sorted differently though)
```{r}
table1
```
These "joins" are related to joins you do with databases if you know SQL. For more on this connection, see Chapter 13 in "R for Data Science" (<http://r4ds.had.co.nz/>). 

## Spreading data

The following table is *untidy*
```{r}
table2
```
because observations (i.e, every year) are spread across multiple rows. To tidy it, identify the column that names the variables, which in this case is `type`, and then the column with the values, which is `count:
```{r}
spread(table2, key = type, value = count)
```

## Separating and uniting 

There are other ways your data might be *untidy*

1. A single column actually contains two or more variables (like a ratio of two variables). In this case, the `separate` function is used.
2. Multiple columns actually contain a single variable and need to be combined. In this case, the `unite` function is used.

To read more about these, see Chapter 12 in "R for Data Science" (<http://r4ds.had.co.nz/>)

# Slicing tidy data with `dplyr`

Now that you have made your data tidy, you probably want to slice and dice it. The `dplyr` package has handy functions for doing just this. Generally, `dplyr` is useful for doing the following five things

1. Pick observations by their values (`filter()`).
2. Reorder the rows (`arrange()`).
3. Pick variables by their names (`select()`).
4. Create new variables with functions of existing variables (`mutate()`).
5. Collapse many values down to a single summary (`summarise()`).

Each of the functions above works in a similar way.

- The first argument is the data frame (*tidy* of course)
- The subsequent arguments describe what to do with the data frame. You can refer to columns in the data frame directly without using $.
- The result is a new data frame.

The polling data you loaded above will be handy here to demonstrate each of the five tasks.

## Filtering rows with `filter()`

Your last assignment included slicing the polling data to include only the Hillary rows from the "now" model. You can do this with `filter`
```{r}
filter(polls, choice == "Clinton", polltypeA == "now")
```
Note that `filter` combines consecutive arguments using the "&". You could equivalently give a single argument with the "&" to get the same slice
```{r}
filter(polls, choice == "Clinton" & polltypeA == "now")
```

## Arrange rows with `arrange()`

The function `arrange` just sorts the rows based on the columns you specify. For example, to sort the polls by the `endDate`,
```{r}
arrange(polls, endDate)
```
and use `desc` to make the sort a descending one,
```{r}
arrange(polls, desc(endDate))
```

## Select columns with select()

The `select` function simple selects specific columns (i.e., variables). To get only the candidate, `adj_pct` (adjusted percentage), candidate, and poll end date, 
```{r}
select(polls, choice, endDate, adj_pct)
```

## Add new variables with mutate()

You may want to add new variables that are functions of other variables. For example, you could create a column that measures how much the adjusted percentage differs from the raw polling value:
```{r}
sm_polls = select(polls, choice, endDate, pct, adj_pct) # just get a small set of columns 
mutate(sm_polls, pct_diff = pct - adj_pct)
```

## Summaries with `summarise()`

The function `summarise` (damn British spelling, though the American one works too apparently) collapses the data frame to a single row:
```{r}
summarize(polls, mean_pct = mean(pct)) # see, America!!!
```
This isn't terribly useful until you use the `group_by` function to do the summarize action on data by "group", which you specify according to values of variables. To see the average for each candidate, group by `choice`,
```{r}
grouped_polls = group_by(polls, choice)
summarize(grouped_polls, mean_pct = mean(adj_pct))
```
or add the polling model type (`polltypeA`),
```{r}
grouped_polls = group_by(polls, choice, polltypeA)
summarize(grouped_polls, mean_pct = mean(adj_pct))
```

[^1]: Wickham, Hadley. 2014. J Stat Softw, 59:1--23. DOI: [10.18637/jss.v059.i10](http://dx.doi.org/10.18637/jss.v059.i10)


# Lab ![](assets/beaker.png)


### Problems

1. Using the polling data, produce a data table that shows the **mean**, **maximum**, and **minimum** `adj_pct` for each combination of pollster, candidate, and polling mode type (`polltypeA`).

2. Recall the gene expression last that was briefly introduced last week:
    ```{r}
    library(readxl)
    imprint = read_excel("babak-etal-2015_imprinted-mouse.xlsx", na = "NaN")
    ```

    Each row is a gene, each column is a tissue type, and each cell contains a gene expression measurement.

    **Make these data tidy!** 
    
    You will need the `gather` function. The first trick here will be first to identify "observation" and then the "key", which is the variable that changes across each observation and which is "gathered". 
    
    The second trick is specifying the columns across which you need to gather. A hint for the second trick is that you can specify the columns you don't want with the "-" sign. That is, with the polling data, for example, every column except `choice` would be `-choice`.
    
    The answer will be deceivingly simple! This is the elegance / frustration of R. 
    
3. Using the tidy data from Problem 2, find the **number of genes** (across all tissue types) that have an **expression value <= 10 and  > 2**. These genes are "paternally imprinted" in the Babak et al. dataset, which means they are only expressed from the maternal copy of the gene. 

    Hint: you will need to count each gene once even if it appears in multiple rows, which can be done with the `distinct` function.

